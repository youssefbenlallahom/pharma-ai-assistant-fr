from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task
from crewai_tools import SerperDevTool, ScrapeWebsiteTool ,SeleniumScrapingTool
from crewai import LLM
from dotenv import load_dotenv
import os
from langchain_groq import ChatGroq
from litellm import completion
from crewai import LLM as CrewLLM
from langchain_community.llms import Ollama
from crewai_tools import SeleniumScrapingTool
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time

load_dotenv()

# Outils
search_tool = SerperDevTool(
    country="fr", 
    locale="fr", 
    location="France")

vidal_tool = ScrapeWebsiteTool(website_url="https://www.vidal.fr")
bdpm_tool = ScrapeWebsiteTool(website_url="https://base-donnees-publique.medicaments.gouv.fr")
passeport_tool = ScrapeWebsiteTool(website_url="https://www.passeportsante.net")
santefr_tool = ScrapeWebsiteTool(website_url="https://www.sante.fr")


class MedicamentScrapingTool(SeleniumScrapingTool):
    def __init__(self, website_url=""):
        super().__init__(website_url=website_url)
    
    def scrape_with_more_button(self, url=None):
        """M√©thode personnalis√©e pour scraper avec clic sur 'voir plus'"""
        if url:
            self.website_url = url
            
        # Utiliser le driver Selenium pour naviguer
        content = self.scrape()
        
        # Tentative de clic sur 'voir plus'
        try:
            # Liste des s√©lecteurs possibles pour 'voir plus'
            selectors = [
                "//button[contains(text(), 'Voir plus de d√©tails')]",
                "//a[contains(text(), 'Voir plus de d√©tails')]",
                "//span[contains(text(), 'voir plus')]",
                "//div[contains(@class, 'readmore')]",
                "//button[contains(@class, 'showmore')]",
                ".toggledetailmed", 
                ".btnplus",
                "a[data-txt='Voir moins de d√©tails']",
                ".readmore-button",
                "a:contains('Voir plus')",
                "button:contains('Voir plus de d√©tails')"
            ]
            
            driver = self._get_driver()
            
            for selector in selectors:
                try:
                    more_button = WebDriverWait(driver, 3).until(
                        EC.element_to_be_clickable((By.XPATH, selector))
                    )
                    more_button.click()
                    time.sleep(2)  # Attendre le chargement du contenu
                    break  # Sortir de la boucle si un bouton a √©t√© cliqu√©
                except:
                    continue
                    
            # R√©cup√©rer le contenu apr√®s avoir cliqu√©
            return driver.page_source
        except:
            # En cas d'√©chec, retourner le contenu initial
            return content
        
med_custom_scraper = MedicamentScrapingTool()

os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")

llm1 = completion(
    model="llama-guard-3-8b",
    api_base="https://api.groq.com/openai/v1",
    api_key=os.getenv("GROQ1_API_KEY"),
    messages=[
        {"role": "system", "content": """üöÄ Assistant M√©dical Expert - Extraction de Donn√©es
R√®gles Absolues :
1. Fran√ßais exclusivement - Aucun terme anglais tol√©r√©
2. Format de sortie strict : 
   - Dictionnaire JSON structur√©
   - Rubriques pr√©d√©finies (Composition, Indications, Posologie...)
3. Sources autoris√©es : Vidal/BDPM/PasseportSant√©/Sante.fr/med.tn
4. Validation crois√©e des informations entre sources
5. Aucun commentaire hors structure demand√©e

Processus :
1. Identifier les sources pertinentes
2. Extraire les donn√©es brutes
3. Uniformiser les unit√©s de mesure
4. D√©tecter les contradictions (‚Üí noter [ALERTE] le cas √©ch√©ant)
5. Structurer selon le sch√©ma m√©dical standard
"""}
    ]
)
llm2 = completion(
    model="llama3-70b-8192",
    api_base="https://api.groq.com/openai/v1",
    api_key=os.getenv("GROQ2_API_KEY"),
    messages=[
        {"role": "system", "content": """üîç Syst√®me Expert M√©dical - Traitement des Connaissances
Objectif : Transformer les donn√©es brutes en savoir exploitable

Directives :
1. Fran√ßais technique strict
2. Structure de sortie :
   - Fiche technique professionnelle (max 400 mots)
   - Encodage s√©mantique pour RAG

√âtapes Obligatoires :
1. Analyse de coh√©rence inter-sources
2. Hi√©rarchisation des informations (crit√®res ATC/OMS)
3. G√©n√©ration de contextes th√©matiques
4. D√©tection des lacunes informationnelles

Format de Sortie :
=== FICHE TECHNIQUE ===
[Nom M√©dicament]
‚ñ∫ Indications : 
   - Principale (Niveau de preuve A)
   - Secondaire (Niveau de preuve B)
‚ñ∫ Posologie : 
   - Adultes : X mg/j
   - Enfants : Y mg/kg
‚ñ∫ Surveillance : 
   - Param√®tres biologiques
   - Signes d'alerte
"""}
    ]
)
llm3 = completion(
    model="llama-3.3-70b-versatile",
    api_base="https://api.groq.com/openai/v1",
    api_key=os.getenv("GROQ3_API_KEY"),
    messages=[
        {"role": "system", "content": """üíä Assistant Pharmaceutique Clinicien
R√®gles de R√©ponse :
1. Fran√ßais professionnel uniquement
2. Structure IMP√âRATIVE :
   - R√©ponse en 50 mots max
   - 1-2 phrases maximum
   - Informations v√©rifi√©es uniquement
3. Interdictions formelles :
   - D√©buter par "R√©ponse :"
   - Mentionner des sources
   - Termes techniques non expliqu√©s
   
Proc√©dure de V√©rification :
1. Croiser avec base de connaissances
2. Filtrer les informations non v√©rifi√©es
3. Adapter au niveau patient/professionnel"""}
    ]
)


@CrewBase
class Medicalchatbot():
    """Assistant m√©dical intelligent utilisant CrewAI"""
    
    agents_config = 'config/agents.yaml'
    tasks_config = 'config/tasks.yaml'
    
    # Nouveaux agents fusionn√©s
    @agent
    def data_miner(self) -> Agent:
        """Fusion de scraper_web et chercheur_medical"""
        return Agent(
            config=self.agents_config['data_miner'],
            tools=[
                search_tool,
                vidal_tool,
                bdpm_tool,
                passeport_tool,
                santefr_tool,
                med_custom_scraper  
            ],
            llm=llm1,
            verbose=True
            
        )
    
    @agent
    def knowledge_engine(self) -> Agent:
        """Fusion de moteur_rag et analyste_de_donnees"""
        return Agent(
            config=self.agents_config['knowledge_engine'],
            tools=[],
            llm=llm2,
            verbose=True
        )
    
    @agent
    def pharma_assistant(self) -> Agent:
        """Assistant pharmaceutique optimis√©"""
        return Agent(
            config=self.agents_config['pharma_assistant'],
            verbose=True,
            llm=llm3
        )
    
    # Nouvelles t√¢ches fusionn√©es
    @task
    def data_mining_task(self) -> Task:
        """Fusion de scraping_task et research_task"""
        return Task(
            config=self.tasks_config['data_mining_task'],
            agent=self.data_miner(),
            output_file='reponse_finale_data_miner.md'
        )
    
    @task
    def knowledge_processing_task(self) -> Task:
        """Fusion de analysis_task et rag_task"""
        return Task(
            config=self.tasks_config['knowledge_processing_task'],
            agent=self.knowledge_engine(),
            dependencies=[self.data_mining_task()],
            output_file='reponse_finale_knowledge.md'
        )
    
    @task
    def response_generation_task(self) -> Task:
        """G√©n√®re une r√©ponse √† la question m√©dicale"""
        return Task(
            config=self.tasks_config['response_generation_task'],
            agent=self.pharma_assistant(),
            dependencies=[self.knowledge_processing_task()],
            output_file='reponse_finale.md'
        )
    
    @crew
    def crew(self) -> Crew:
        """Assemble l'√©quipe m√©dicale virtuelle"""
        return Crew(
            agents=[
                self.data_miner(),
                self.knowledge_engine(),
                self.pharma_assistant()
            ],
            tasks=[
                self.data_mining_task(),
                self.knowledge_processing_task(),
                self.response_generation_task()
            ],
            process=Process.sequential,
            verbose=True
        )
